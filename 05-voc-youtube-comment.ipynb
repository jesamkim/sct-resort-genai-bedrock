{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f96857ae-7c33-4610-9165-88fcb572ddde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-api-python-client\n",
      "  Downloading google_api_python_client-2.151.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 (from google-api-python-client)\n",
      "  Downloading google_auth-2.35.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 (from google-api-python-client)\n",
      "  Downloading google_api_core-2.22.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (4.25.4)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Downloading proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.32.3)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client)\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.7.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2024.7.4)\n",
      "Downloading google_api_python_client-2.151.0-py2.py3-none-any.whl (12.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m144.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.22.0-py3-none-any.whl (156 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.35.0-py2.py3-none-any.whl (208 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.0/209.0 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.9/220.9 kB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: uritemplate, pyasn1-modules, proto-plus, httplib2, googleapis-common-protos, cachetools, google-auth, google-auth-httplib2, google-api-core, google-api-python-client\n",
      "Successfully installed cachetools-5.5.0 google-api-core-2.22.0 google-api-python-client-2.151.0 google-auth-2.35.0 google-auth-httplib2-0.2.0 googleapis-common-protos-1.65.0 httplib2-0.22.0 proto-plus-1.25.0 pyasn1-modules-0.4.1 uritemplate-4.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef8fbcb6-5a05-4175-94b3-7c450f436362",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anthropic in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.39.0)\n",
      "Collecting textblob\n",
      "  Downloading textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anthropic) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anthropic) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anthropic) (2.9.1)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anthropic) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anthropic) (4.12.2)\n",
      "Requirement already satisfied: nltk>=3.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->anthropic) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->anthropic) (1.2.2)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->anthropic) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->anthropic) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk>=3.8->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk>=3.8->textblob) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk>=3.8->textblob) (4.66.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.23.3)\n",
      "Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.3/626.3 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: textblob\n",
      "Successfully installed textblob-0.18.0.post0\n"
     ]
    }
   ],
   "source": [
    "!pip install anthropic textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5424cc79-0c17-48b6-94ee-12b6871729d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/nltk/metrics/association.py:26: UserWarning: A NumPy version >=1.23.5 and <2.3.0 is required for this version of SciPy (detected version 1.22.4)\n",
      "  from scipy.stats import fisher_exact\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small prompt: 2790\n",
      "small prompt: 4766\n",
      "small 3.5 sonnet Input Tokens: 1921, Output Tokens: 1181\n",
      "Video Analysis DataFrame:\n",
      "       VideoID                                       Title Analysis-type  \\\n",
      "0  fbIaogYiZt0  🌊현시점 가장 힙한 클럽 캐비😎 | #shorts #캐리비안베이 #에버랜드론         small   \n",
      "\n",
      "                                            Analysis  \n",
      "0  이 YouTube 비디오 콘텐츠 분석 결과는 다음과 같습니다:\\n\\n1. 주요 주제...  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "from anthropic import AnthropicBedrock\n",
    "import random\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "\n",
    "# YouTube API 초기화\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "youtubeAPI_key = 'XXXXXXXXXXXXXXXXXXXXX'     ## API key 변경 필요\n",
    "youtube = build(api_service_name, api_version, developerKey=youtubeAPI_key)\n",
    "\n",
    "# AnthropicBedrock 클라이언트 초기화\n",
    "client = AnthropicBedrock(aws_region=\"us-west-2\")\n",
    "\n",
    "def analyze_video_content_small(video_id, video_df, comments_df, max_chunk_length=5000):\n",
    "    # 비디오 정보 가져오기\n",
    "    video_info = video_df[video_df['VideoID'] == video_id].iloc[0]\n",
    "    video_title = video_info['Title']\n",
    "    video_description = video_info['Description']\n",
    "\n",
    "    # 해당 비디오의 댓글 필터링\n",
    "    video_comments = comments_df[comments_df['VideoID'] == video_id]\n",
    "\n",
    "    # 모든 텍스트 결합\n",
    "    all_text = f\"Comments:\\n\"\n",
    "    \n",
    "    for _, comment in video_comments.iterrows():\n",
    "        all_text += f\"Top Level Comment: {comment['topLevelComment']}\\n\"\n",
    "        if comment['ThreadComment']:\n",
    "            all_text += f\"Thread Comment: {comment['ThreadComment']}\\n\"\n",
    "        all_text += \"\\n\"\n",
    "\n",
    "    # 텍스트 청크로 나누기\n",
    "    # chunks = chunk_text(all_text, max_length=max_chunk_length)\n",
    "\n",
    "    all_analyses = []\n",
    "    # for chunk in chunks:\n",
    "    prompt = f\"\"\"\n",
    "    비디오 제목: {video_info['Title']}\n",
    "    비디오 설명: {video_info['Description']}\n",
    "    \n",
    "        다음 YouTube 비디오 콘텐츠(제목, 설명, Top Level Comment, Thread Comment 포함)를 분석해주세요. 당신의 임무는 다음과 같습니다:\n",
    "\n",
    "        1. 제목, 설명, Top Level Comment, Thread Comment, 좋야요 수를 바탕으로 비디오에서 논의된 주요 주제나 테마를 요약해주세요.\n",
    "        2. Thread Comment 분석시 Top Level Comment의 내용과 Thread Comment의 Timestamp를 보고 Context를 같이 분석해주세요.\n",
    "        3. 댓글의 전반적인 감정(긍정적, 부정적, 중립적)을 Context에 맞게 파악해주고 각 감정별로 원문을 정리해주세요.\n",
    "        4. Thread Comment가 많이 있는 Top Level Comment의 댓글을 분석하고 주된 논의 내용 및 반복적인 키워드를 나열해주고 대표적인 내용의 원문을 보여주세요.\n",
    "        5. 댓글 작성자들이 반복적으로 제기하는 질문, 우려사항, 관심사를 강조해주고 원문을 보여주세요.\n",
    "        6. 댓글에서 나타나는 중요한 의견 차이나 논쟁을 파악해주고(좋아요 수를 참고해주세요) 원문을 보여주세요. \n",
    "        7. 비디오 제작자에게 제시된 주목할 만한 피드백이나 제안을 확인해주고 원문을 보여주세요.\n",
    "\n",
    "        비디오 설명이 제공하는 컨텍스트와 댓글 작성자들 간의 상호작용을 고려하여 종합적인 분석을 제공해주세요. 모든 응답은 한국어로 작성해 주세요.\n",
    "        분석에 근거가 되는 원문을 포함해서 작성해주세요.\n",
    "        Video Content:\n",
    "        {all_text}\n",
    "        \"\"\"\n",
    "    print(f\"small prompt: {len(prompt)}\")\n",
    "    print(f\"small prompt: {len(prompt.encode('utf-8'))}\")\n",
    "\n",
    "    response = client.messages.create(\n",
    "            model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "            max_tokens=4000,\n",
    "            temperature=0.5,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    input_tokens = response.usage.input_tokens\n",
    "    output_tokens = response.usage.output_tokens\n",
    "    print(f\"small 3.5 sonnet Input Tokens: {input_tokens}, Output Tokens: {output_tokens}\")\n",
    "\n",
    "\n",
    "    result = response.content[0].text\n",
    "    all_analyses.append(result)\n",
    "\n",
    "    return \" \".join(all_analyses)\n",
    "\n",
    "def get_top_comments(comments, n=100):\n",
    "    return sorted(comments, key=lambda x: x['likeCount'], reverse=True)[:n]\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "def cluster_comments(comments, n_clusters=5):\n",
    "    vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "    X = vectorizer.fit_transform([c['topLevelComment'] for c in comments])\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(X)\n",
    "    return kmeans.labels_\n",
    "\n",
    "def analyze_video_content_large(video_id, video_df, comments_df, max_chunk_length=5000):\n",
    "    video_info = video_df[video_df['VideoID'] == video_id].iloc[0]\n",
    "    video_comments = comments_df[comments_df['VideoID'] == video_id]\n",
    "    \n",
    "    # 인기 댓글 분석\n",
    "    top_comments = get_top_comments(video_comments.to_dict('records'), n=100)\n",
    "    \n",
    "    # 감정 분석\n",
    "    sentiments = [analyze_sentiment(c['topLevelComment']) for c in top_comments]\n",
    "    avg_sentiment = sum(sentiments) / len(sentiments)\n",
    "    \n",
    "    # 클러스터링\n",
    "    cluster_labels = cluster_comments(video_comments.to_dict('records'))\n",
    "    \n",
    "    # Thread가 많은 댓글 필터링\n",
    "    comments_with_threads = [c for c in video_comments.to_dict('records') if c['ThreadComment']]\n",
    "    top_thread_comments = sorted(comments_with_threads, key=lambda x: len(x['ThreadComment']), reverse=True)[:10]\n",
    "    \n",
    "    \n",
    "    # Thread가 많은 댓글 그룹핑 및 분석\n",
    "    thread_comment_analysis = \"\"\n",
    "    input_tokens_result =0\n",
    "    output_tokens_result =0\n",
    "    for c in top_thread_comments:\n",
    "        top_comment = c['topLevelComment']\n",
    "        thread_comments = c['ThreadComment']\n",
    "        \n",
    "        # 각 그룹에 대해 감정 분석, 주요 주제 및 키워드 분석\n",
    "        all_comments_text = f\"Top Level Comment: {top_comment}\\n\" + \"\\n\".join(thread_comments)\n",
    "        thread_sentiment = analyze_sentiment(all_comments_text)\n",
    "        \n",
    "        # 대표적인 댓글과 주요 주제 추출\n",
    "        prompt= f\"\"\"Top Level Comment와 Thread Comments를 포함한 다음 댓글 그룹을 분석해주세요:Top Level Comment: {top_comment} \n",
    "        Thread Comments: {''.join([f'- {t}, ' for t in thread_comments])} \n",
    "        \n",
    "        1. 분석에 근거가 되는 원문을 포함해서 이 그룹에서 논의된 주요 주제나 테마를 요약해주세요.\n",
    "        2. 분석에 근거가 되는 원문을 포함해서 전체적인 감정(긍정적, 부정적, 중립적)을 파악해주세요.\n",
    "        3. 분석에 근거가 되는 원문을 포함해서 반복적으로 나타나는 키워드나 표현을 요약해주세요.\n",
    "        4. 분석에 근거가 되는 원문을 포함해서 중요한 논쟁이나 의견 차이가 있는 경우 이를 식별하고 설명해주세요.\n",
    "        5. 분석에 근거가 되는 원문을 포함해서 주요 논의 내용 및 전반적인 톤을 요약해주세요.\n",
    "        6. 분석근거의 원문을 생략없이 최대한 많이 포함해서 보여주세요.\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"haiku len prompt: {len(prompt)}\")\n",
    "        print(f\"haiku encode utf8 len prompt: {len(prompt.encode('utf-8'))}\")\n",
    "        \n",
    "        response = client.messages.create(\n",
    "            model=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "            max_tokens=1500,\n",
    "            temperature=0.5,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        input_tokens = response.usage.input_tokens\n",
    "        output_tokens = response.usage.output_tokens\n",
    "        print(f\"haiku each Input Tokens: {input_tokens}, Output Tokens: {output_tokens}\")\n",
    "\n",
    "        input_tokens_result += input_tokens\n",
    "        output_tokens_result += output_tokens\n",
    "        \n",
    "        thread_analysis = response.content[0].text\n",
    "        \n",
    "        thread_comment_analysis += f\"\\nTop Level Comment: {top_comment[:50]}...\\n\"\n",
    "        thread_comment_analysis += f\"Sentiment: {thread_sentiment}\\n\"\n",
    "        thread_comment_analysis += f\"Analysis:\\n{thread_analysis}\\n\\n\"\n",
    "        \n",
    "    print(f\"haiku input token: {input_tokens_result}\")\n",
    "    print(f\"haiku output token: {output_tokens_result}\")\n",
    "        \n",
    "    \n",
    "    # 분석 결과 요약\n",
    "    summary = f\"\"\"비디오 제목: {video_info['Title']}\n",
    "    비디오 설명: {video_info['Description']}\n",
    "       \n",
    "    1. 상위 인기 댓글 (좋아요 순 상위 30개):\n",
    "    {\n",
    "        ''.join([f\"   - {c['topLevelComment'][:20]}... (좋아요: {c['likeCount']}... {c['ThreadComment'][:200]}) \" for c in top_comments[:30]])\n",
    "    }\n",
    "    \n",
    "    2. 주요 댓글 클러스터:\n",
    "    {\n",
    "        ''.join([f\"   클러스터 {i}: {Counter(cluster_labels)[i]}개 댓글 \" for i in range(100)])\n",
    "    }\n",
    "    \n",
    "    3. Thread가 많은 상위 10개 댓글 분석:\n",
    "    {thread_comment_analysis}\n",
    "    \n",
    "    4. 전반적인 분석:\n",
    "      1) 분석에 근거가 되는 원문을 포함해서 댓글의 전반적인 감정(긍정적, 부정적, 중립적)을 파악해주세요.\n",
    "      2) 분석에 근거가 되는 원문을 포함해서 토론의 주된 톤(예: 열정적, 비판적, 정보 제공적, 유머러스 등)을 결정해주세요.\n",
    "      3) 분석에 근거가 되는 원문을 포함해서 댓글 작성자들이 반복적으로 제기하는 질문, 우려사항, 관심사를 강조해주세요.\n",
    "      4) 분석에 근거가 되는 원문을 포함해서 댓글에서 나타나는 중요한 의견 차이나 논쟁을 파악해주세요.\n",
    "      5) 분석에 근거가 되는 원문을 포함해서 비디오 제작자에게 제시된 주목할 만한 피드백이나 제안을 확인해주세요.\n",
    "      6) 분석에 근거가 되는 원문을 포함해서 Thread가 많은 상위 10개 댓글 요약 분석에 대한 내용을 포함해서 별도로 작성해주고 안에 원문은 그대로 유지하세요.\n",
    "\n",
    "        비디오 설명이 제공하는 컨텍스트와 댓글 작성자들 간의 상호작용을 고려하여 종합적인 분석을 제공해주세요.\n",
    "        분석에 근거가 되는 원문을 생략없이 최대한 많이 포함해서 작성해주세요.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"large summary prompt: {len(prompt)}\")\n",
    "    print(f\"large summary prompt: {len(prompt.encode('utf-8'))}\")\n",
    "    \n",
    "    response = client.messages.create(\n",
    "            model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "            max_tokens=4000,\n",
    "            temperature=0.7,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": summary}\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    input_tokens = response.usage.input_tokens\n",
    "    output_tokens = response.usage.output_tokens\n",
    "    print(f\"large 3.5 sonnet input token: {input_tokens}\")\n",
    "    print(f\"large 3.5 sonnet output token: {output_tokens}\")\n",
    "\n",
    "    result = response.content[0].text\n",
    "\n",
    "    return result\n",
    "    \n",
    "# Function to get replies for a specific comment\n",
    "def get_replies(youtube, parent_id, video_id):\n",
    "    replies = []\n",
    "    request = youtube.comments().list(\n",
    "        part=\"snippet\",\n",
    "        parentId=parent_id,\n",
    "        textFormat=\"plainText\",\n",
    "        maxResults=100\n",
    "    )\n",
    "    \n",
    "    while request:\n",
    "        response = request.execute()\n",
    "        replies.extend([{\n",
    "            'Timestamp': item['snippet']['publishedAt'],\n",
    "            'Username': item['snippet']['authorDisplayName'],\n",
    "            'VideoID': video_id,\n",
    "            'topLevelComment': response['items'][0]['snippet']['textDisplay'],  # Avoid redundant indexing\n",
    "            'ThreadComment': item['snippet']['textDisplay'],\n",
    "            'likeCount': item['snippet']['likeCount']\n",
    "            # 'Date': item['snippet'].get('updatedAt', item['snippet']['publishedAt'])\n",
    "        } for item in response['items']])\n",
    "\n",
    "        request = youtube.comments().list_next(request, response)\n",
    "\n",
    "    return replies\n",
    "\n",
    "\n",
    "# Function to get all comments (including replies) for a single video\n",
    "def get_comments_for_video(youtube, video_id):\n",
    "    all_comments = []\n",
    "    request = youtube.commentThreads().list(\n",
    "        part=\"snippet\",\n",
    "        videoId=video_id,\n",
    "        textFormat=\"plainText\",\n",
    "        maxResults=100\n",
    "    )\n",
    "    \n",
    "    while request:\n",
    "        response = request.execute()\n",
    "        for item in response['items']:\n",
    "            top_comment = item['snippet']['topLevelComment']['snippet']\n",
    "            all_comments.append({\n",
    "                'Timestamp': top_comment['publishedAt'],\n",
    "                'Username': top_comment['authorDisplayName'],\n",
    "                'VideoID': video_id,\n",
    "                'topLevelComment': top_comment['textDisplay'],\n",
    "                'ThreadComment': '',\n",
    "                'likeCount': top_comment['likeCount']\n",
    "                # 'Date': top_comment.get('updatedAt', top_comment['publishedAt'])\n",
    "            })\n",
    "\n",
    "            # Fetch replies if there are any\n",
    "            if item['snippet']['totalReplyCount'] > 0:\n",
    "                all_comments.extend(get_replies(youtube, item['id'], video_id))\n",
    "\n",
    "        request = youtube.commentThreads().list_next(request, response)\n",
    "\n",
    "    return all_comments\n",
    "\n",
    "\n",
    "# Function to get video details (title and description)\n",
    "def get_video_details(youtube, video_id):\n",
    "    request = youtube.videos().list(\n",
    "        part='snippet',\n",
    "        id=video_id\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    if response['items']:\n",
    "        snippet = response['items'][0]['snippet']\n",
    "        return {\n",
    "            'VideoID': video_id,\n",
    "            'Title': snippet['title'],\n",
    "            'Description': snippet['description']\n",
    "        }\n",
    "    return None\n",
    "\n",
    "# 비디오 정보와 댓글 가져오기\n",
    "video_details = []\n",
    "all_comments = []\n",
    "video_ids = ['fbIaogYiZt0'] #['IenW7-OrBVU', 'fbIaogYiZt0'] #['fbIaogYiZt0'] #['fbIaogYiZt0']   #['IenW7-OrBVU', 'i1PUY_vJxZs']\n",
    "\n",
    "for video_id in video_ids:\n",
    "    video_info = get_video_details(youtube, video_id)\n",
    "    if video_info:\n",
    "        video_details.append(video_info)\n",
    "    video_comments = get_comments_for_video(youtube, video_id)\n",
    "    all_comments.extend(video_comments)\n",
    "\n",
    "video_df = pd.DataFrame(video_details)\n",
    "comments_df = pd.DataFrame(all_comments)\n",
    "\n",
    "# 각 비디오 분석\n",
    "analysis_results = []\n",
    "for _, row in video_df.iterrows():\n",
    "    video_id = row['VideoID']\n",
    "    title = row['Title']\n",
    "    \n",
    "    if len(comments_df[comments_df['VideoID'] == video_id ]) > 1000:\n",
    "        analysis_type = 'large'\n",
    "        analysis = analyze_video_content_large(video_id, video_df, comments_df)\n",
    "    else:\n",
    "        analysis_type = 'small'\n",
    "        analysis = analyze_video_content_small(video_id, video_df, comments_df)\n",
    "    \n",
    "    analysis_results.append({\n",
    "        'VideoID': video_id,\n",
    "        'Title': title,\n",
    "        'Analysis-type': analysis_type,\n",
    "        'Analysis': analysis\n",
    "    })\n",
    "\n",
    "analysis_df = pd.DataFrame(analysis_results)\n",
    "print(\"Video Analysis DataFrame:\")\n",
    "print(analysis_df)\n",
    "\n",
    "# Result save as CSV\n",
    "video_ids_string = \"_\".join(video_ids)\n",
    "filename = f'youtube_analysis_{video_ids_string}.csv'\n",
    "analysis_df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dcf5194-c26b-42b8-a8a8-f74832789b0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VideoID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Analysis-type</th>\n",
       "      <th>Analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fbIaogYiZt0</td>\n",
       "      <td>🌊현시점 가장 힙한 클럽 캐비😎 | #shorts #캐리비안베이 #에버랜드론</td>\n",
       "      <td>small</td>\n",
       "      <td>이 YouTube 비디오 콘텐츠 분석 결과는 다음과 같습니다:\\n\\n1. 주요 주제...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       VideoID                                       Title Analysis-type  \\\n",
       "0  fbIaogYiZt0  🌊현시점 가장 힙한 클럽 캐비😎 | #shorts #캐리비안베이 #에버랜드론         small   \n",
       "\n",
       "                                            Analysis  \n",
       "0  이 YouTube 비디오 콘텐츠 분석 결과는 다음과 같습니다:\\n\\n1. 주요 주제...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a630d1b4-47fc-48b4-931c-d5d7b7a3cd91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
